# Financial Insight Generator (FIG)

Financial Insight Generator (FIG) is a modular Python toolkit that turns raw
transaction-level data (CSV/Excel) into:

- Clean, validated datasets  
- Useful financial KPIs and segments  
- Human-readable insight reports and an interactive CLI “assistant”

Think of it as a small, extensible **junior financial analyst** you can run
locally today and later plug into an LLM or web UI.

---

## Table of Contents

- [Features](#features)
- [Architecture Overview](#architecture-overview)
- [Directory Layout](#directory-layout)
- [Installation](#installation)
- [Configuration (`config.yaml`)](#configuration-configyaml)
- [Sample Dataset](#sample-dataset)
- [Usage](#usage)
  - [1. Run the data pipeline](#1-run-the-data-pipeline)
  - [2. Run analytics demo](#2-run-analytics-demo)
  - [3. Generate a full insight report](#3-generate-a-full-insight-report)
  - [4. Use the CLI + interactive assistant](#4-use-the-cli--interactive-assistant)
- [Multilingual Support (English + Indonesian)](#multilingual-support-english--indonesian)
  - [Language selection (config + CLI)](#language-selection-config--cli)
  - [How translations are implemented](#how-translations-are-implemented)
  - [Bahasa Indonesia quick guide](#bahasa-indonesia-quick-guide)
- [Running Tests](#running-tests)
- [Roadmap & Future Enhancements](#roadmap--future-enhancements)
- [What This Demonstrates (AI Engineering Skills)](#what-this-demonstrates-ai-engineering-skills)
- [Tech Stack](#tech-stack)
- [License](#license)
- [Contact](#contact)

---

## Features

- **Data ingestion & cleaning**
  - Load CSV/Excel transaction data.
  - Validate required columns and types.
  - Normalize dates, filter invalid rows, and save a cleaned dataset.

- **Analytics & KPIs**
  - Overall metrics (revenue, cost, gross profit, gross margin, order counts).
  - Time series (e.g., revenue by day/month).
  - Segment metrics:
    - Category
    - Product
    - Customer
    - Channel
  - Simple trend analysis (month-over-month).
  - Simple anomaly detection on recent daily revenue.

- **Insight generation**
  - Template-based text report summarizing:
    - Overview
    - Segment highlights
    - Trend analysis
    - Daily anomaly check
  - Report is designed so a future LLM could replace or augment it.

- **CLI + interactive “chat-like” assistant**
  - `python -m fig.cli`:
    - Loads config, runs pipeline, builds metrics, prints a text report.
    - Optional interactive shell with commands like:
      - `summary`
      - `top categories`
      - `top products`
      - `top customers`
      - `top channels`
      - `trend`
      - `anomaly`
      - `time series`

- **Clean, extensible architecture**
  - `src/fig` package with clear layers:
    - `config` → `data_loader` → `validation` → `preprocessing`
      → `analytics` → `insights` → `cli` / `chatbot`.
  - Easy to extend:
    - Add new KPIs or segment analyses in `analytics.py`.
    - Swap or augment template-based insights with LLMs later.

---

## Architecture Overview

The core flow:

```text
raw CSV/Excel
      ↓
   data_loader       (I/O only)
      ↓
   validation        (schema + value checks)
      ↓
  preprocessing      (clean/normalize)
      ↓
   analytics         (metrics, KPIs, segments, trends, anomaly)
      ↓
   insights          (textual report, i18n-aware)
      ↓
     cli / chatbot   (CLI entrypoint + interactive assistant)
````

---

## Directory Layout

High-level layout (not exhaustive):

```text
.
├── README.md
├── requirements.txt
├── config.yaml
├── data/
│   ├── raw/
│   │   └── sample_transactions.csv
│   └── processed/
│       └── cleaned_transactions.csv   # generated by pipeline
├── reports/
│   └── financial_insights.txt        # generated report (optional)
├── src/
│   └── fig/
│       ├── __init__.py
│       ├── config.py
│       ├── data_loader.py
│       ├── validation.py
│       ├── preprocessing.py
│       ├── analytics.py
│       ├── insights.py
│       ├── chatbot.py
│       ├── cli.py
│       ├── i18n.py
│       └── locales/
│           ├── en.yaml
│           └── id.yaml
├── tests/
│   ├── test_config.py
│   ├── test_data_loader.py
│   ├── test_analytics.py
│   └── test_insights.py
├── run_data_pipeline.py
├── run_analytics_demo.py
└── run_insights_report.py
```

---

## Installation

### Requirements

* Python **3.10+** recommended (tested with 3.12).
* `pip` for dependency management.

### Steps

From the project root:

```bash
python3 -m venv .venv
source .venv/bin/activate  # Windows (PowerShell): .venv\Scripts\Activate.ps1

pip install --upgrade pip
pip install -r requirements.txt
```

Make sure the `src` directory is on `PYTHONPATH` when running scripts directly:

```bash
export PYTHONPATH=src
# Windows (cmd):    set PYTHONPATH=src
# Windows (PowerShell): $env:PYTHONPATH="src"
```

---

## Configuration (`config.yaml`)

The main configuration file is `config.yaml`. Key sections:

```yaml
data:
  input_path: "data/raw/sample_transactions.csv"
  date_format: "%Y-%m-%d"
  parse_dates: true

columns:
  date: "order_date"
  amount: "total_price"
  cost: "cost"
  category: "category"
  product: "product_name"
  customer_id: "customer_id"
  channel: "sales_channel"

analytics:
  time_granularity: "month"        # day, week, or month
  top_n: 5
  anomaly_lookback_days: 30
  anomaly_sigma_threshold: 2.0

output:
  save_clean_data: true
  clean_data_path: "data/processed/cleaned_transactions.csv"
  save_metrics: true
  metrics_path: "data/processed/metrics.json"
  save_report: true
  report_path: "reports/financial_insights.txt"

ui:
  language: "en"  # or "id" for Bahasa Indonesia
```

* `data`: where to load raw transactions from.
* `columns`: mapping from logical fields to actual CSV column names.
* `analytics`: how to compute segments/trends/anomaly.
* `output`: where to store cleaned data, metrics, and the text report.
* `ui.language`: default language for user-facing text.

---

## Sample Dataset

The `data/raw/sample_transactions.csv` file is a synthetic dataset useful for:

* Trying out the pipeline.
* Demonstrating the analytics and report output.
* Running tests and examples.

You can swap this for your own file by updating `config.yaml → data.input_path` and adjusting `columns`.

---

## Usage

### 1. Run the data pipeline

Runs loading, validation, cleaning, and saves a cleaned CSV.

```bash
export PYTHONPATH=src

python run_data_pipeline.py
```

You should see printed sections:

* `Validation Report`
* `Cleaning Summary`
* `Sample of Cleaned Data`

And a file `data/processed/cleaned_transactions.csv` is written.

---

### 2. Run analytics demo

Runs the pipeline, computes metrics, and prints summaries.

```bash
export PYTHONPATH=src

python run_analytics_demo.py
```

Prints:

* Validation + cleaning summary.
* Overall metrics.
* Time series (daily/monthly revenue).
* Top categories.
* Monthly trend summary.
* Last-day anomaly check.

---

### 3. Generate a full insight report

This script runs everything and prints the full text report (Overview, Segments, Trend, Anomaly). It also respects the `ui.language` field in `config.yaml`.

```bash
export PYTHONPATH=src

python run_insights_report.py
```

* With `ui.language: "en"` → report in English.
* With `ui.language: "id"` → report in Bahasa Indonesia.

Optionally, you can configure `output.report_path` to write the report to a file as well.

---

### 4. Use the CLI + interactive assistant

The CLI integrates the whole flow and optionally starts a simple chat-like interface.

```bash
export PYTHONPATH=src

# Print full report (default language from config)
python -m fig.cli --config config.yaml

# Print full report and then start interactive mode
python -m fig.cli --config config.yaml --interactive
```

Helpful flags:

* `--no-report` – Skip printing the report on startup (go straight to interactive mode).
* `--interactive` – Start the chat-style assistant.
* `--lang` / `-l` – Override language without editing config:

  ```bash
  # Force Indonesian regardless of config.yaml
  python -m fig.cli --config config.yaml --lang id
  ```

In interactive mode, you can type:

* `summary`
* `top categories`
* `top products`
* `top customers`
* `top channels`
* `trend`
* `anomaly`
* `time series`
* `help`
* `exit` / `quit` / `q`

---

## Multilingual Support (English + Indonesian)

FIG supports **two languages** for user-facing text:

* English (`en`) – default.
* Bahasa Indonesia (`id`).

All user-visible strings in:

* The text report (`insights.py`),
* The CLI banner (`cli.py`),
* The interactive assistant (`chatbot.py`),

go through a simple i18n layer.

### Language selection (config + CLI)

**1. Config (default)**

`config.yaml`:

```yaml
ui:
  language: "en"  # or "id"
```

* Set to `"en"` for English output.
* Set to `"id"` for Indonesian output.
* If omitted or invalid, `en` is used as a safe default.

**2. CLI flag override**

You can override the config at runtime:

```bash
# Force English
python -m fig.cli --config config.yaml --lang en

# Force Indonesian
python -m fig.cli --config config.yaml --lang id
```

Priority:

1. CLI `--lang` (highest).
2. `ui.language` in `config.yaml`.
3. Default `"en"`.

### How translations are implemented

* Translations live in YAML files under `src/fig/locales`:

  * `en.yaml` – English strings.
  * `id.yaml` – Indonesian strings.

* There is a small helper module `src/fig/i18n.py` that:

  * Loads and caches YAML per language.

  * Exposes a function:

    ```python
    from fig.i18n import get_translator

    t = get_translator("id")
    text = t("report.section.overview")  # -> "1. Gambaran Umum"
    ```

  * Supports named placeholders, e.g.:

    ```yaml
    report:
      overview:
        total_revenue: "- Total pendapatan sebesar {total_revenue} dari {n_transactions} transaksi."
    ```

    which is called from Python as:

    ```python
    t(
        "report.overview.total_revenue",
        total_revenue=_fmt_currency(total_revenue),
        n_transactions=_fmt_number(n_transactions, 0),
    )
    ```

* If a key is missing in `id.yaml`, the translator falls back to `en.yaml`.
  This prevents crashes if new keys are added and not yet translated.

This design is intentionally simple and “portfolio-friendly”: it shows an understanding of i18n patterns without pulling in heavy dependencies.

### Bahasa Indonesia quick guide

#### Instalasi singkat

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
export PYTHONPATH=src
```

#### Menjalankan laporan dalam Bahasa Indonesia

1. Ubah `config.yaml`:

   ```yaml
   ui:
     language: "id"
   ```

2. Jalankan:

   ```bash
   python run_insights_report.py
   ```

   atau dengan CLI:

   ```bash
   python -m fig.cli --config config.yaml --lang id
   ```

Laporan dan teks di mode interaktif akan tampil dalam Bahasa Indonesia, sementara perhitungan dan angka tetap sama.

---

## Running Tests

Tests live in the `tests/` directory and cover:

* Config loading and validation.
* Data loading and preprocessing.
* Core analytics (KPIs, time series, segments).
* Insight report generation (including English + a smoke test for Indonesian headings).

Run all tests:

```bash
export PYTHONPATH=src
pytest
```

---

## Roadmap & Future Enhancements

Some ideas for future iterations:

* **LLM Integration**

  * Use the existing `metrics_bundle` as a structured context for an LLM.
  * Generate richer, conversational insights based on the same metrics.

* **Web API / UI**

  * Wrap the pipeline + insights in a FastAPI or Flask service.
  * Build a simple web dashboard to browse metrics and reports.

* **More Languages**

  * Add more locale files: `locales/fr.yaml`, `locales/es.yaml`, etc.
  * Extend tests to cover additional languages.

* **Richer Analytics**

  * Cohort analysis, retention, CLV.
  * More robust anomaly detection models.

---

## What This Demonstrates (AI Engineering Skills)

This project is intentionally structured to highlight:

* **Clean separation of concerns**

  * Data loading, validation, preprocessing, analytics, insights, and UX are modular.
* **Production-minded design**

  * Configuration-driven behavior (`config.yaml`).
  * Clear tests and small helper scripts.
* **Multilingual UX**

  * Simple but realistic i18n implementation (YAML locales + translation helper).
  * Config + CLI override for language selection.
* **LLM-readiness**

  * `metrics_bundle` is a compact, structured representation ideal for LLM prompts.

---

## Tech Stack

* Python 3.10+
* pandas, numpy
* PyYAML
* pytest

No heavy frameworks; everything is intentionally lightweight and transparent.

---

## License

You can adapt this project to your own needs.
(If you plan to open-source it, you can drop in a standard license here, e.g. MIT.)

---

## Contact

If you have feedback or ideas, feel free to reach out or open an issue in the repository that contains this project.