# Configuration for Financial Insight Generator

data:
  # Path to the input CSV/Excel file with raw transactions
  input_path: "data/raw/sample_transactions.csv"

  # Optional: specify the date format if your dates are in a known format.
  # If omitted, the loader will let pandas infer the format.
  date_format: "%Y-%m-%d"
  parse_dates: true

columns:
  # Column mapping: logical field -> column name in your CSV

  # Required fields
  date: "order_date"
  amount: "total_price"

  # Optional fields (comment out or delete if not present in your data)
  cost: "cost"
  category: "category"
  product: "product_name"
  customer_id: "customer_id"
  channel: "sales_channel"

analytics:
  # Default analytics options (we'll use these in Phase 5+)
  time_granularity: "month"        # one of: day, week, month
  top_n: 5                         # for "top N" categories/products/customers
  anomaly_lookback_days: 30
  anomaly_sigma_threshold: 2.0

output:
  # Control what gets saved to disk (used in later phases)
  save_clean_data: true
  clean_data_path: "data/processed/cleaned_transactions.csv"

  save_metrics: true
  metrics_path: "data/processed/metrics.json"

  save_report: true
  report_path: "reports/financial_insights.txt"

ui:
  # Language for user-facing output (CLI, reports, etc.)
  # Supported in this phase: "en" (English, default), "id" (Bahasa Indonesia)
  language: "en"

llm:
  # Global toggle for LLM features. When false, FIG behaves as a pure, template-based tool.
  enabled: true

  # Logical provider name; used by fig.llm_client to decide which SDK / HTTP client to call.
  # Examples: "openai", "gemini", "deepseek", "custom".
  provider: "openai"

  # Default model name for the chosen provider.
  # For OpenAI, examples include: "gpt-4.1-mini", "gpt-4o-mini", etc.
  model: "gpt-4.1-mini"

  # Sampling parameters. You can tweak these per project.
  temperature: 0.3
  max_tokens: 800

  # Name of the environment variable that stores your API key.
  # Do NOT commit the key itself; just set this env var locally.
  api_key_env_var: "OPENAI_API_KEY"

  # Network safety limits (seconds).
  timeout_seconds: 30

  # Report/assistant behavior mode:
  # - "template"  -> use only the built-in template-based generator (no LLM calls)
  # - "llm"       -> use only the LLM-based generator
  # - "hybrid"    -> use the template output as context for the LLM
  mode: "template"

  # Safety limit for how much structured context we send into prompts
  # (metrics bundle, samples of the cleaned DataFrame, etc.).
  max_context_chars: 12000